{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZun6UtHazyQR4EChjV72F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dorisdong888/Python_Practise/blob/main/Extracting_Stock_Data_Via_Web_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZWjz6aEezHX"
      },
      "outputs": [],
      "source": [
        "#!pip install pandas==1.3.3\n",
        "#!pip install requests==2.26.0\n",
        "!mamba install bs4==4.10.0 -y\n",
        "!mamba install html5lib==1.1 -y\n",
        "!pip install lxml==4.6.4\n",
        "#!pip install plotly==5.3.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "0RS1TXwTfPh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First we must use the request library to downlaod the webpage, and extract the text. We will extract Netflix stock data\n",
        "# https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html.\n",
        "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html\"\n",
        "\n",
        "data  = requests.get(url).text"
      ],
      "metadata": {
        "id": "ph9H-WP5fRkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(data, 'html5lib')"
      ],
      "metadata": {
        "id": "32y3mSS4fxEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#turn the html table into a pandas dataframe\n",
        "netflix_data = pd.DataFrame(columns=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n",
        "\n",
        "# First we isolate the body of the table which contains all the information\n",
        "# Then we loop through each row and find all the column values for each row\n",
        "for row in soup.find(\"tbody\").find_all('tr'):\n",
        "    col = row.find_all(\"td\")\n",
        "    date = col[0].text\n",
        "    Open = col[1].text\n",
        "    high = col[2].text\n",
        "    low = col[3].text\n",
        "    close = col[4].text\n",
        "    adj_close = col[5].text\n",
        "    volume = col[6].text\n",
        "    \n",
        "    # Finally we append the data of each row to the table\n",
        "    netflix_data = netflix_data.append({\"Date\":date, \"Open\":Open, \"High\":high, \"Low\":low, \"Close\":close, \"Adj Close\":adj_close, \"Volume\":volume}, ignore_index=True)    "
      ],
      "metadata": {
        "id": "8jF3ScCyf2EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use the pandas read_html function using the url\n",
        "read_html_pandas_data = pd.read_html(url)"
      ],
      "metadata": {
        "id": "3ewFdy-Jf7Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Or convert the BeautifulSoup object to a string\n",
        "read_html_pandas_data = pd.read_html(str(soup))"
      ],
      "metadata": {
        "id": "S0aLg5GkfqGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_dataframe = read_html_pandas_data[0]\n",
        "\n",
        "netflix_dataframe.head()"
      ],
      "metadata": {
        "id": "dtWHSTbZiON3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amazon_data.shape\n",
        "amazon_data.iloc[60,1]"
      ],
      "metadata": {
        "id": "k7kCFi1rnExs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}